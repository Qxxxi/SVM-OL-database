{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 双模态多特征融合实验\n\n**视觉侧**: CLIP (高层抽象) + OFfts (面部细节)\n\n**文本侧**: BERT\n\n**融合策略**:\n1. Concat - 简单拼接 (基线)\n2. Weighted Sum - 可学习权重加权\n3. Gated - 门控融合\n4. Hierarchical - 层次融合 (先视觉内融合，再跨模态)\n5. Bilinear - 双线性交互\n6. Cross-Attention - 跨模态注意力\n7. Tensor - 张量融合"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================== GPU 选择 ====================\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 改成你想用的卡号\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # 显存按需分配"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 特征配置 ====================\n",
    "FOLD = 0  # 修改这里切换fold (0, 1, 2)\n",
    "\n",
    "FEATURES_CONFIG = {\n",
    "    'clip': {\n",
    "        'name': f'{FOLD}CLIP',\n",
    "        'file': f'./data2025/fold{FOLD}_visual_clip.pkl',\n",
    "        'shape': (16, 512),\n",
    "        'modality': 'visual'\n",
    "    },\n",
    "    'offt': {\n",
    "        'name': f'{FOLD}OFfts',\n",
    "        'file': f'./data2025/fold{FOLD}_visual_OFfts.pkl',\n",
    "        'shape': (30, 709),\n",
    "        'modality': 'visual'\n",
    "    },\n",
    "    'bert': {\n",
    "        'name': f'{FOLD}BERT',\n",
    "        'file': f'./data2025/fold{FOLD}_textual_bert.pkl',\n",
    "        'shape': (82, 768),\n",
    "        'modality': 'text'\n",
    "    }\n",
    "}\n",
    "\n",
    "LABEL_FILE = f'./data2025/fold{FOLD}_labels.pkl'\n",
    "\n",
    "# ==================== 实验配置 ====================\n",
    "NUM_RUNS = 5\n",
    "\n",
    "# ==================== 保存路径 ====================\n",
    "feature_names = '__'.join([cfg['name'] for cfg in FEATURES_CONFIG.values()])\n",
    "SAVE_DIR = f'./data2025/resm/{feature_names}/fusion_tri'\n",
    "\n",
    "print(f\"Fold: {FOLD}\")\n",
    "print(f\"特征配置:\")\n",
    "for key, cfg in FEATURES_CONFIG.items():\n",
    "    print(f\"  {key}: {cfg['shape']} ({cfg['modality']})\")\n",
    "print(f\"重复训练次数: {NUM_RUNS}\")\n",
    "print(f\"保存路径: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model, backend as K\n",
    "from keras.layers import (Input, Dense, Conv1D, LSTM, Concatenate, Add, Multiply,\n",
    "                          Attention, GlobalAveragePooling1D, Dropout, \n",
    "                          BatchNormalization, Lambda, Layer, Flatten)\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utilz import load_features\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU: {len(tf.config.list_physical_devices('GPU'))} available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载各特征\n",
    "feature_data = {}\n",
    "for key, cfg in FEATURES_CONFIG.items():\n",
    "    data = load_features(cfg['file'])\n",
    "    feature_data[key] = {\n",
    "        'train': np.asarray(data['train']),\n",
    "        'test': np.asarray(data['test']),\n",
    "        'shape': cfg['shape']\n",
    "    }\n",
    "    print(f\"{key}: train={feature_data[key]['train'].shape}, test={feature_data[key]['test'].shape}\")\n",
    "\n",
    "# 加载标签\n",
    "label = load_features(LABEL_FILE)\n",
    "y_train = np.asarray(label['train'])\n",
    "y_test = np.asarray(label['test'])\n",
    "\n",
    "# 便捷变量\n",
    "X_clip_train = feature_data['clip']['train']\n",
    "X_clip_test = feature_data['clip']['test']\n",
    "X_offt_train = feature_data['offt']['train']\n",
    "X_offt_test = feature_data['offt']['test']\n",
    "X_bert_train = feature_data['bert']['train']\n",
    "X_bert_test = feature_data['bert']['test']\n",
    "\n",
    "print(f\"\\n训练集: {len(y_train)}, 测试集: {len(y_test)}\")\n",
    "\n",
    "# 类别信息\n",
    "class_labels = ['Bored', 'Happy', 'Interested', 'Tired', 'Confused']\n",
    "num_classes = 5\n",
    "\n",
    "# 类别权重\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"类别权重: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 编码器定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_SHAPE = FEATURES_CONFIG['clip']['shape']\n",
    "OFFT_SHAPE = FEATURES_CONFIG['offt']['shape']\n",
    "BERT_SHAPE = FEATURES_CONFIG['bert']['shape']\n",
    "\n",
    "def build_clip_encoder(input_shape=None):\n",
    "    \"\"\"\n",
    "    CLIP编码器: Conv1D x 3 + LSTM -> 64维\n",
    "    \"\"\"\n",
    "    if input_shape is None:\n",
    "        input_shape = CLIP_SHAPE\n",
    "    \n",
    "    inp = Input(input_shape, name='clip_input')\n",
    "    \n",
    "    h = Conv1D(64, 3, 1, 'same', kernel_regularizer=l2(0.001))(inp)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = tf.keras.layers.ReLU()(h)\n",
    "    \n",
    "    h = Conv1D(64, 1, 1, 'same', kernel_regularizer=l2(0.001))(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = tf.keras.layers.ReLU()(h)\n",
    "    \n",
    "    h = Conv1D(64, 3, 1, 'same', kernel_regularizer=l2(0.001))(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = tf.keras.layers.ReLU()(h)\n",
    "    \n",
    "    out = LSTM(64, activation='relu', dropout=0.2, recurrent_dropout=0.2)(h)\n",
    "    \n",
    "    return inp, out  # (batch, 64)\n",
    "\n",
    "\n",
    "def build_offt_encoder(input_shape=None):\n",
    "    \"\"\"\n",
    "    OpenFace编码器: Conv1D x 2 + LSTM -> 64维\n",
    "    处理面部动作单元等细节特征\n",
    "    \"\"\"\n",
    "    if input_shape is None:\n",
    "        input_shape = OFFT_SHAPE\n",
    "    \n",
    "    inp = Input(input_shape, name='offt_input')\n",
    "    \n",
    "    h = Conv1D(128, 3, 1, 'same', kernel_regularizer=l2(0.001))(inp)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = tf.keras.layers.ReLU()(h)\n",
    "    \n",
    "    h = Conv1D(64, 3, 1, 'same', kernel_regularizer=l2(0.001))(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = tf.keras.layers.ReLU()(h)\n",
    "    \n",
    "    out = LSTM(64, activation='relu', dropout=0.2, recurrent_dropout=0.2)(h)\n",
    "    \n",
    "    return inp, out  # (batch, 64)\n",
    "\n",
    "\n",
    "def build_bert_encoder(input_shape=None):\n",
    "    \"\"\"\n",
    "    BERT编码器: Conv1D + Attention + Pool -> 128维\n",
    "    \"\"\"\n",
    "    if input_shape is None:\n",
    "        input_shape = BERT_SHAPE\n",
    "    \n",
    "    inp = Input(input_shape, name='bert_input')\n",
    "    \n",
    "    q = Conv1D(64, 3, 1, kernel_regularizer=l2(0.001))(inp)\n",
    "    v = Conv1D(64, 3, 1, kernel_regularizer=l2(0.001))(inp)\n",
    "    attn = Attention()([q, v])\n",
    "    \n",
    "    q_pool = GlobalAveragePooling1D()(q)\n",
    "    attn_pool = GlobalAveragePooling1D()(attn)\n",
    "    \n",
    "    out = Concatenate()([q_pool, attn_pool])  # (batch, 128)\n",
    "    \n",
    "    return inp, out\n",
    "\n",
    "\n",
    "print(\"编码器定义完成\")\n",
    "print(f\"  CLIP:  {CLIP_SHAPE} -> 64维\")\n",
    "print(f\"  OFfts: {OFFT_SHAPE} -> 64维\")\n",
    "print(f\"  BERT:  {BERT_SHAPE} -> 128维\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 融合策略定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================== 融合策略 1: Concat ====================\ndef fusion_concat(clip_feat, offt_feat, bert_feat):\n    \"\"\"\n    简单拼接: 64 + 64 + 128 = 256维\n    \"\"\"\n    return Concatenate(name='fusion_concat')([clip_feat, offt_feat, bert_feat])\n\n\n# ==================== 融合策略 2: Weighted Sum ====================\ndef fusion_weighted_sum(clip_feat, offt_feat, bert_feat):\n    \"\"\"\n    三路可学习权重加权求和\n    输出: 128维\n    \"\"\"\n    # 投影到相同维度\n    clip_proj = Dense(128, kernel_regularizer=l2(0.001))(clip_feat)\n    offt_proj = Dense(128, kernel_regularizer=l2(0.001))(offt_feat)\n    bert_proj = Dense(128, kernel_regularizer=l2(0.001))(bert_feat)\n    \n    # 计算权重\n    concat_all = Concatenate()([clip_proj, offt_proj, bert_proj])\n    weights = Dense(3, activation='softmax', kernel_regularizer=l2(0.001))(concat_all)\n    \n    w1 = Lambda(lambda x: tf.expand_dims(x[:, 0], -1))(weights)\n    w2 = Lambda(lambda x: tf.expand_dims(x[:, 1], -1))(weights)\n    w3 = Lambda(lambda x: tf.expand_dims(x[:, 2], -1))(weights)\n    \n    # 加权求和\n    fused = Add(name='fusion_weighted_sum')([\n        Multiply()([clip_proj, w1]),\n        Multiply()([offt_proj, w2]),\n        Multiply()([bert_proj, w3])\n    ])\n    \n    return fused\n\n\n# ==================== 融合策略 3: Gated ====================\ndef fusion_gated(clip_feat, offt_feat, bert_feat):\n    \"\"\"\n    三路门控融合 (每个特征独立门控)\n    输出: 128维\n    \"\"\"\n    # 投影到相同维度\n    clip_proj = Dense(128, kernel_regularizer=l2(0.001))(clip_feat)\n    offt_proj = Dense(128, kernel_regularizer=l2(0.001))(offt_feat)\n    bert_proj = Dense(128, kernel_regularizer=l2(0.001))(bert_feat)\n    \n    # 每个特征独立的门控\n    concat_all = Concatenate()([clip_proj, offt_proj, bert_proj])\n    \n    gate_clip = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(concat_all)\n    gate_offt = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(concat_all)\n    gate_bert = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(concat_all)\n    \n    gated_clip = Multiply()([clip_proj, gate_clip])\n    gated_offt = Multiply()([offt_proj, gate_offt])\n    gated_bert = Multiply()([bert_proj, gate_bert])\n    \n    fused = Add(name='fusion_gated')([gated_clip, gated_offt, gated_bert])\n    \n    return fused\n\n\n# ==================== 融合策略 4: Hierarchical ====================\ndef fusion_hierarchical(clip_feat, offt_feat, bert_feat):\n    \"\"\"\n    层次融合:\n    1. 先融合视觉特征 (CLIP + OFfts)\n    2. 再与文本特征融合\n    输出: 128维\n    \"\"\"\n    # 视觉内融合 (CLIP + OFfts)\n    vis_concat = Concatenate()([clip_feat, offt_feat])  # 128维\n    vis_gate = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(vis_concat)\n    \n    clip_proj = Dense(64, kernel_regularizer=l2(0.001))(clip_feat)\n    offt_proj = Dense(64, kernel_regularizer=l2(0.001))(offt_feat)\n    vis_proj = Concatenate()([clip_proj, offt_proj])  # 128维\n    \n    vis_fused = Multiply()([vis_gate, vis_proj])  # 门控后的视觉特征\n    \n    # 跨模态融合 (视觉 + 文本)\n    combined = Concatenate()([vis_fused, bert_feat])  # 256维\n    cross_gate = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(combined)\n    \n    vis_final = Dense(128, kernel_regularizer=l2(0.001))(vis_fused)\n    tex_final = Dense(128, kernel_regularizer=l2(0.001))(bert_feat)\n    \n    fused = Add(name='fusion_hierarchical')([\n        Multiply()([cross_gate, vis_final]), \n        Multiply()([Lambda(lambda x: 1-x)(cross_gate), tex_final])\n    ])\n    \n    return fused\n\n\n# ==================== 融合策略 5: Bilinear ====================\ndef fusion_bilinear(clip_feat, offt_feat, bert_feat):\n    \"\"\"\n    双线性融合: 捕捉特征间的二阶交互\n    输出: 128维\n    \"\"\"\n    # 投影到较小维度\n    clip_proj = Dense(32, kernel_regularizer=l2(0.001))(clip_feat)\n    offt_proj = Dense(32, kernel_regularizer=l2(0.001))(offt_feat)\n    bert_proj = Dense(32, kernel_regularizer=l2(0.001))(bert_feat)\n    \n    # 双线性交互: clip-offt\n    clip_exp = Lambda(lambda x: tf.expand_dims(x, 2))(clip_proj)\n    offt_exp = Lambda(lambda x: tf.expand_dims(x, 1))(offt_proj)\n    bilinear_vis = Lambda(lambda x: x[0] * x[1])([clip_exp, offt_exp])\n    bilinear_vis_flat = Flatten()(bilinear_vis)  # 1024维\n    \n    # 双线性交互: vis-bert (用clip代表视觉)\n    bert_exp = Lambda(lambda x: tf.expand_dims(x, 1))(bert_proj)\n    bilinear_cross = Lambda(lambda x: x[0] * x[1])([clip_exp, bert_exp])\n    bilinear_cross_flat = Flatten()(bilinear_cross)  # 1024维\n    \n    # 合并并压缩\n    bilinear_all = Concatenate()([bilinear_vis_flat, bilinear_cross_flat])  # 2048维\n    bilinear_compressed = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(bilinear_all)\n    \n    # 残差连接\n    concat_orig = Concatenate()([clip_feat, offt_feat, bert_feat])\n    concat_proj = Dense(128, kernel_regularizer=l2(0.001))(concat_orig)\n    \n    fused = Add(name='fusion_bilinear')([bilinear_compressed, concat_proj])\n    \n    return fused\n\n\n# ==================== 融合策略 6: Cross-Attention ====================\nclass MultiHeadCrossAttention(Layer):\n    def __init__(self, units=64, **kwargs):\n        super().__init__(**kwargs)\n        self.units = units\n        \n    def build(self, input_shape):\n        self.wq = Dense(self.units, kernel_regularizer=l2(0.001))\n        self.wk = Dense(self.units, kernel_regularizer=l2(0.001))\n        self.wv = Dense(self.units, kernel_regularizer=l2(0.001))\n        super().build(input_shape)\n        \n    def call(self, query, key_value):\n        q = self.wq(query)\n        k = self.wk(key_value)\n        v = self.wv(key_value)\n        \n        scores = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(self.units, tf.float32))\n        attn_weights = tf.nn.softmax(scores, axis=-1)\n        output = tf.matmul(attn_weights, v)\n        return output\n    \n    def get_config(self):\n        config = super().get_config()\n        config.update({'units': self.units})\n        return config\n\n\ndef fusion_cross_attention(clip_feat, offt_feat, bert_feat):\n    \"\"\"\n    跨模态注意力融合\n    输出: 192维\n    \"\"\"\n    # 扩展维度\n    clip_seq = Lambda(lambda x: tf.expand_dims(x, 1))(clip_feat)\n    offt_seq = Lambda(lambda x: tf.expand_dims(x, 1))(offt_feat)\n    bert_seq = Lambda(lambda x: tf.expand_dims(x, 1))(bert_feat)\n    \n    # 视觉特征拼接作为KV\n    vis_seq = Concatenate(axis=1)([clip_seq, offt_seq])  # (batch, 2, dim)\n    \n    # 文本查询视觉\n    cross_attn_t2v = MultiHeadCrossAttention(64, name='cross_attn_t2v')\n    bert_attended = cross_attn_t2v(bert_seq, vis_seq)\n    bert_out = Lambda(lambda x: tf.squeeze(x, 1))(bert_attended)  # 64维\n    \n    # 视觉查询文本\n    cross_attn_v2t = MultiHeadCrossAttention(64, name='cross_attn_v2t')\n    clip_attended = cross_attn_v2t(clip_seq, bert_seq)\n    offt_attended = cross_attn_v2t(offt_seq, bert_seq)\n    clip_out = Lambda(lambda x: tf.squeeze(x, 1))(clip_attended)  # 64维\n    offt_out = Lambda(lambda x: tf.squeeze(x, 1))(offt_attended)  # 64维\n    \n    fused = Concatenate(name='fusion_cross_attention')([clip_out, offt_out, bert_out])  # 192维\n    return fused\n\n\n# ==================== 融合策略 7: Tensor ====================\ndef fusion_tensor(clip_feat, offt_feat, bert_feat):\n    \"\"\"\n    张量融合: [f1;1] ⊗ [f2;1] ⊗ [f3;1] 的简化版\n    输出: 128维\n    \"\"\"\n    # 投影到较小维度\n    clip_proj = Dense(16, kernel_regularizer=l2(0.001))(clip_feat)\n    offt_proj = Dense(16, kernel_regularizer=l2(0.001))(offt_feat)\n    bert_proj = Dense(16, kernel_regularizer=l2(0.001))(bert_feat)\n    \n    # 添加常数1\n    clip_with_1 = Lambda(lambda x: tf.concat([x, tf.ones_like(x[:, :1])], axis=1))(clip_proj)  # 17维\n    offt_with_1 = Lambda(lambda x: tf.concat([x, tf.ones_like(x[:, :1])], axis=1))(offt_proj)  # 17维\n    bert_with_1 = Lambda(lambda x: tf.concat([x, tf.ones_like(x[:, :1])], axis=1))(bert_proj)  # 17维\n    \n    # 两两外积 (简化版，避免三维张量过大)\n    # clip ⊗ offt\n    clip_exp = Lambda(lambda x: tf.expand_dims(x, 2))(clip_with_1)\n    offt_exp = Lambda(lambda x: tf.expand_dims(x, 1))(offt_with_1)\n    tensor_vis = Lambda(lambda x: x[0] * x[1])([clip_exp, offt_exp])  # (batch, 17, 17)\n    tensor_vis_flat = Flatten()(tensor_vis)  # 289维\n    \n    # vis ⊗ bert (用压缩后的vis)\n    vis_compressed = Dense(17, kernel_regularizer=l2(0.001))(tensor_vis_flat)\n    vis_exp = Lambda(lambda x: tf.expand_dims(x, 2))(vis_compressed)\n    bert_exp = Lambda(lambda x: tf.expand_dims(x, 1))(bert_with_1)\n    tensor_all = Lambda(lambda x: x[0] * x[1])([vis_exp, bert_exp])  # (batch, 17, 17)\n    tensor_flat = Flatten()(tensor_all)  # 289维\n    \n    fused = Dense(128, activation='relu', kernel_regularizer=l2(0.001), name='fusion_tensor')(tensor_flat)\n    \n    return fused\n\n\nprint(\"融合策略定义完成！\")\nprint(\"  1. Concat: 简单拼接 -> 256维\")\nprint(\"  2. Weighted Sum: 加权求和 -> 128维\")\nprint(\"  3. Gated: 三路门控 -> 128维\")\nprint(\"  4. Hierarchical: 层次融合 -> 128维\")\nprint(\"  5. Bilinear: 双线性交互 -> 128维\")\nprint(\"  6. Cross-Attention: 跨模态注意力 -> 192维\")\nprint(\"  7. Tensor: 张量融合 -> 128维\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def build_model(fusion_method='concat', learning_rate=0.0005):\n    \"\"\"\n    构建三特征融合模型\n    \"\"\"\n    K.clear_session()\n    gc.collect()\n    \n    # 构建编码器\n    clip_inp, clip_feat = build_clip_encoder()\n    offt_inp, offt_feat = build_offt_encoder()\n    bert_inp, bert_feat = build_bert_encoder()\n    \n    # 选择融合策略\n    fusion_methods = {\n        'concat': fusion_concat,\n        'weighted_sum': fusion_weighted_sum,\n        'gated': fusion_gated,\n        'hierarchical': fusion_hierarchical,\n        'bilinear': fusion_bilinear,\n        'cross_attention': fusion_cross_attention,\n        'tensor': fusion_tensor\n    }\n    \n    fused = fusion_methods[fusion_method](clip_feat, offt_feat, bert_feat)\n    \n    # 分类头\n    h = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(fused)\n    h = BatchNormalization()(h)\n    h = Dropout(0.5)(h)\n    h = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(h)\n    h = Dropout(0.3)(h)\n    output = Dense(num_classes, activation='softmax', name='output')(h)\n    \n    model = Model(inputs=[clip_inp, offt_inp, bert_inp], outputs=output)\n    \n    model.compile(\n        optimizer=Adam(learning_rate=learning_rate),\n        loss=keras.losses.SparseCategoricalCrossentropy(),\n        metrics=['acc']\n    )\n    \n    return model\n\n\nprint(\"模型构建函数完成\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_run(fusion_method, run_id):\n",
    "    \"\"\"单次训练\"\"\"\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = build_model(fusion_method=fusion_method, learning_rate=0.0005)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True, mode='max', verbose=0),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=5, min_lr=1e-7, mode='max', verbose=0)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=[X_clip_train, X_offt_train, X_bert_train],\n",
    "        y=y_train,\n",
    "        batch_size=16,\n",
    "        epochs=50,\n",
    "        validation_data=([X_clip_test, X_offt_test, X_bert_test], y_test),\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 评估\n",
    "    pred = model.predict([X_clip_test, X_offt_test, X_bert_test], verbose=0)\n",
    "    pred_labels = pred.argmax(axis=1)\n",
    "    test_acc = np.mean(pred_labels == y_test)\n",
    "    \n",
    "    report = classification_report(y_test, pred_labels, target_names=class_labels,\n",
    "                                   digits=4, output_dict=True, zero_division=0)\n",
    "    f1_macro = report['macro avg']['f1-score']\n",
    "    cm = confusion_matrix(y_test, pred_labels)\n",
    "    \n",
    "    acc_key = 'acc' if 'acc' in history.history else 'accuracy'\n",
    "    val_acc_key = 'val_acc' if 'val_acc' in history.history else 'val_accuracy'\n",
    "    best_train_acc = max(history.history[acc_key])\n",
    "    best_epoch = history.history[val_acc_key].index(max(history.history[val_acc_key])) + 1\n",
    "    \n",
    "    result = {\n",
    "        'run_id': run_id,\n",
    "        'test_acc': test_acc,\n",
    "        'f1_macro': f1_macro,\n",
    "        'train_acc': best_train_acc,\n",
    "        'best_epoch': best_epoch,\n",
    "        'params': model.count_params(),\n",
    "        'confusion_matrix': cm,\n",
    "        'history': history.history,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def train_and_evaluate(fusion_method, num_runs=5):\n",
    "    \"\"\"多次训练取最好\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"融合策略: {fusion_method.upper()} (重复 {num_runs} 次)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    \n",
    "    all_runs = []\n",
    "    best_model = None\n",
    "    best_acc = -1\n",
    "    best_idx = -1\n",
    "    \n",
    "    for run_id in range(1, num_runs + 1):\n",
    "        print(f\"  Run {run_id}/{num_runs}...\", end=\" \")\n",
    "        result = train_single_run(fusion_method, run_id)\n",
    "        print(f\"ACC: {result['test_acc']:.4f}, F1: {result['f1_macro']:.4f}\")\n",
    "        \n",
    "        if result['test_acc'] > best_acc:\n",
    "            if best_model is not None:\n",
    "                del best_model\n",
    "            best_model = result['model']\n",
    "            best_acc = result['test_acc']\n",
    "            best_idx = run_id - 1\n",
    "        else:\n",
    "            del result['model']\n",
    "        \n",
    "        result_copy = {k: v for k, v in result.items() if k != 'model'}\n",
    "        all_runs.append(result_copy)\n",
    "        \n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    accs = [r['test_acc'] for r in all_runs]\n",
    "    f1s = [r['f1_macro'] for r in all_runs]\n",
    "    \n",
    "    mean_acc, std_acc = np.mean(accs), np.std(accs)\n",
    "    max_acc, min_acc = np.max(accs), np.min(accs)\n",
    "    mean_f1, std_f1 = np.mean(f1s), np.std(f1s)\n",
    "    \n",
    "    best_run = all_runs[best_idx]\n",
    "    \n",
    "    model_path = f'{SAVE_DIR}/model_{fusion_method}.tf'\n",
    "    best_model.save(model_path)\n",
    "    \n",
    "    print(f\"\\n  统计: ACC = {mean_acc:.4f} ± {std_acc:.4f} (max={max_acc:.4f}, min={min_acc:.4f})\")\n",
    "    print(f\"        F1  = {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "    print(f\"  最佳: Run {best_run['run_id']}, ACC = {best_run['test_acc']:.4f}\")\n",
    "    \n",
    "    del best_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    results = {\n",
    "        'method': fusion_method,\n",
    "        'num_runs': num_runs,\n",
    "        'all_accs': accs,\n",
    "        'all_f1s': f1s,\n",
    "        'mean_acc': mean_acc,\n",
    "        'std_acc': std_acc,\n",
    "        'max_acc': max_acc,\n",
    "        'min_acc': min_acc,\n",
    "        'mean_f1': mean_f1,\n",
    "        'std_f1': std_f1,\n",
    "        'best_run': best_run,\n",
    "        'test_acc': best_run['test_acc'],\n",
    "        'f1_macro': best_run['f1_macro'],\n",
    "        'train_acc': best_run['train_acc'],\n",
    "        'best_epoch': best_run['best_epoch'],\n",
    "        'params': best_run['params'],\n",
    "        'confusion_matrix': best_run['confusion_matrix'],\n",
    "        'history': best_run['history']\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"训练评估函数完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 运行实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fusion_methods = ['concat', 'weighted_sum', 'gated', 'hierarchical', 'bilinear', 'cross_attention', 'tensor']\n\nprint(\"=\"*60)\nprint(\"双模态多特征融合实验 (CLIP + OFfts + BERT)\")\nprint(\"=\"*60)\nprint(f\"Fold: {FOLD}\")\nprint(f\"特征: CLIP {CLIP_SHAPE} + OFfts {OFFT_SHAPE} + BERT {BERT_SHAPE}\")\nprint(f\"融合策略: {fusion_methods}\")\nprint(f\"重复次数: {NUM_RUNS}\")\nprint(f\"保存路径: {SAVE_DIR}\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行所有实验\n",
    "all_results = {}\n",
    "\n",
    "for method in fusion_methods:\n",
    "    results = train_and_evaluate(method, num_runs=NUM_RUNS)\n",
    "    all_results[method] = results\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"所有实验完成！\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 结果汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果表格\n",
    "results_df = pd.DataFrame({\n",
    "    'Method': [r['method'].upper() for r in all_results.values()],\n",
    "    'Best ACC': [f\"{r['max_acc']:.4f}\" for r in all_results.values()],\n",
    "    'Mean±Std': [f\"{r['mean_acc']:.4f}±{r['std_acc']:.4f}\" for r in all_results.values()],\n",
    "    'Best F1': [f\"{r['f1_macro']:.4f}\" for r in all_results.values()],\n",
    "    'F1 Mean±Std': [f\"{r['mean_f1']:.4f}±{r['std_f1']:.4f}\" for r in all_results.values()],\n",
    "    'Params': [f\"{r['params']:,}\" for r in all_results.values()],\n",
    "})\n",
    "\n",
    "results_df['best_acc_float'] = [r['max_acc'] for r in all_results.values()]\n",
    "results_df = results_df.sort_values('best_acc_float', ascending=False).drop('best_acc_float', axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(f\"融合策略对比结果 (CLIP + OFfts + BERT, Fold {FOLD})\")\n",
    "print(\"=\"*90)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "csv_path = f'{SAVE_DIR}/results_summary.csv'\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\n结果已保存至: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 可视化\nfig, axes = plt.subplots(1, 2, figsize=(16, 5))\n\nsorted_results = sorted(all_results.values(), key=lambda x: x['max_acc'], reverse=True)\nmethods = [r['method'].upper() for r in sorted_results]\nmax_accs = [r['max_acc'] for r in sorted_results]\nmean_accs = [r['mean_acc'] for r in sorted_results]\nstd_accs = [r['std_acc'] for r in sorted_results]\nmax_f1s = [r['f1_macro'] for r in sorted_results]\nmean_f1s = [r['mean_f1'] for r in sorted_results]\nstd_f1s = [r['std_f1'] for r in sorted_results]\n\ncolors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c', '#e67e22']\nx = np.arange(len(methods))\n\nbars1 = axes[0].bar(x, max_accs, color=colors[:len(methods)], alpha=0.8, label='Best')\naxes[0].errorbar(x, mean_accs, yerr=std_accs, fmt='o', color='black', capsize=5, capthick=2, label='Mean±Std')\naxes[0].set_ylabel('Test Accuracy', fontsize=12)\naxes[0].set_title(f'Test Accuracy (CLIP+OFfts+BERT, Fold {FOLD})', fontsize=14, fontweight='bold')\naxes[0].set_ylim([0, 1])\naxes[0].set_xticks(x)\naxes[0].set_xticklabels(methods, rotation=45, ha='right')\naxes[0].legend()\nfor bar, acc in zip(bars1, max_accs):\n    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{acc:.4f}', ha='center', fontweight='bold', fontsize=8)\n\nbars2 = axes[1].bar(x, max_f1s, color=colors[:len(methods)], alpha=0.8, label='Best')\naxes[1].errorbar(x, mean_f1s, yerr=std_f1s, fmt='o', color='black', capsize=5, capthick=2, label='Mean±Std')\naxes[1].set_ylabel('F1 Score (Macro)', fontsize=12)\naxes[1].set_title(f'F1 Score (CLIP+OFfts+BERT, Fold {FOLD})', fontsize=14, fontweight='bold')\naxes[1].set_ylim([0, 1])\naxes[1].set_xticks(x)\naxes[1].set_xticklabels(methods, rotation=45, ha='right')\naxes[1].legend()\nfor bar, f1 in zip(bars2, max_f1s):\n    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{f1:.4f}', ha='center', fontweight='bold', fontsize=8)\n\nplt.tight_layout()\nplt.savefig(f'{SAVE_DIR}/accuracy_comparison.png', dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 混淆矩阵\nfig, axes = plt.subplots(2, 4, figsize=(20, 10))\naxes = axes.flatten()\n\nfor idx, (method, results) in enumerate(all_results.items()):\n    if idx >= 7:\n        break\n    ax = axes[idx]\n    cm = results['confusion_matrix']\n    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n                xticklabels=class_labels, yticklabels=class_labels,\n                ax=ax, vmin=0, vmax=1)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('True')\n    ax.set_title(f\"{method.upper()} (ACC: {results['test_acc']:.4f})\", fontweight='bold')\n\n# 隐藏多余的subplot\nif len(all_results) < 8:\n    axes[7].axis('off')\n\nplt.tight_layout()\nplt.savefig(f'{SAVE_DIR}/confusion_matrices.png', dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 最终总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(all_results.items(), key=lambda x: x[1]['max_acc'], reverse=True)\n",
    "best_method, best_result = sorted_results[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"双模态多特征融合实验 - 最终总结\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n【实验配置】\")\n",
    "print(f\"  Fold: {FOLD}\")\n",
    "print(f\"  视觉特征: CLIP {CLIP_SHAPE} + OFfts {OFFT_SHAPE}\")\n",
    "print(f\"  文本特征: BERT {BERT_SHAPE}\")\n",
    "print(f\"  重复次数: {NUM_RUNS}\")\n",
    "\n",
    "print(\"\\n【融合策略排名】\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'排名':<4}{'策略':<18}{'Best ACC':<12}{'Mean±Std':<18}{'Best F1':<10}{'参数量':<12}\")\n",
    "print(\"-\" * 80)\n",
    "for rank, (method, r) in enumerate(sorted_results, 1):\n",
    "    mean_std = f\"{r['mean_acc']:.4f}±{r['std_acc']:.4f}\"\n",
    "    print(f\"{rank:<4}{method.upper():<18}{r['max_acc']:<12.4f}{mean_std:<18}{r['f1_macro']:<10.4f}{r['params']:<12,}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n【最佳融合策略】: {best_method.upper()}\")\n",
    "print(f\"  Best ACC: {best_result['max_acc']:.4f}\")\n",
    "print(f\"  Mean ACC: {best_result['mean_acc']:.4f} ± {best_result['std_acc']:.4f}\")\n",
    "print(f\"  Best F1:  {best_result['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n【保存路径】: {SAVE_DIR}\")\n",
    "print(\"=\"*80)\n",
    "print(\"实验完成！\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}