{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双模态多特征融合实验 (Face版)\n",
    "\n",
    "**视觉侧**: CLIP (高层抽象) + Face (面部图像CNN)\n",
    "\n",
    "**文本侧**: BERT\n",
    "\n",
    "**融合策略**:\n",
    "1. Concat - 简单拼接 (基线)\n",
    "2. Weighted Sum - 可学习权重加权\n",
    "3. Gated - 门控融合\n",
    "4. Hierarchical - 层次融合\n",
    "5. Bilinear - 双线性交互\n",
    "6. Cross-Attention - 跨模态注意力\n",
    "7. Tensor - 张量融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================== GPU 选择 ====================\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 改成你想用的卡号\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # 显存按需分配"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 特征配置 ====================\n",
    "FOLD = 0  # 修改这里切换fold (0, 1, 2)\n",
    "\n",
    "FEATURES_CONFIG = {\n",
    "    'clip': {\n",
    "        'name': f'{FOLD}CLIP',\n",
    "        'file': f'./data2025/fold{FOLD}_visual_clip.pkl',\n",
    "        'shape': (16, 512),\n",
    "        'modality': 'visual'\n",
    "    },\n",
    "    'face': {\n",
    "        'name': f'{FOLD}Face',\n",
    "        'file': f'./data2025/fold{FOLD}_visual_face.pkl',\n",
    "        'shape': (16, 224, 224, 3),  # 原始图像\n",
    "        'modality': 'visual'\n",
    "    },\n",
    "    'bert': {\n",
    "        'name': f'{FOLD}BERT',\n",
    "        'file': f'./data2025/fold{FOLD}_textual_bert.pkl',\n",
    "        'shape': (82, 768),\n",
    "        'modality': 'text'\n",
    "    }\n",
    "}\n",
    "\n",
    "LABEL_FILE = f'./data2025/fold{FOLD}_labels.pkl'\n",
    "\n",
    "# ==================== 实验配置 ====================\n",
    "NUM_RUNS = 5\n",
    "\n",
    "# ==================== 保存路径 ====================\n",
    "feature_names = '__'.join([cfg['name'] for cfg in FEATURES_CONFIG.values()])\n",
    "SAVE_DIR = f'./data2025/resm/{feature_names}/fusion_tri'\n",
    "\n",
    "print(f\"Fold: {FOLD}\")\n",
    "print(f\"特征配置:\")\n",
    "for key, cfg in FEATURES_CONFIG.items():\n",
    "    print(f\"  {key}: {cfg['shape']} ({cfg['modality']})\")\n",
    "print(f\"重复训练次数: {NUM_RUNS}\")\n",
    "print(f\"保存路径: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model, backend as K\n",
    "from keras.layers import (Input, Dense, Conv1D, Conv2D, LSTM, Concatenate, Add, Multiply,\n",
    "                          Attention, GlobalAveragePooling1D, GlobalAveragePooling2D, \n",
    "                          Dropout, BatchNormalization, Lambda, Layer, Flatten,\n",
    "                          TimeDistributed, MaxPooling2D, Reshape)\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utilz import load_features\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU: {len(tf.config.list_physical_devices('GPU'))} available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载各特征\n",
    "feature_data = {}\n",
    "for key, cfg in FEATURES_CONFIG.items():\n",
    "    data = load_features(cfg['file'])\n",
    "    train_data = np.asarray(data['train'])\n",
    "    test_data = np.asarray(data['test'])\n",
    "    \n",
    "    # Face图像归一化到0-1\n",
    "    if key == 'face':\n",
    "        if train_data.max() > 1:\n",
    "            train_data = train_data.astype('float32') / 255.0\n",
    "            test_data = test_data.astype('float32') / 255.0\n",
    "    \n",
    "    feature_data[key] = {\n",
    "        'train': train_data,\n",
    "        'test': test_data,\n",
    "        'shape': cfg['shape']\n",
    "    }\n",
    "    print(f\"{key}: train={feature_data[key]['train'].shape}, test={feature_data[key]['test'].shape}\")\n",
    "\n",
    "# 加载标签\n",
    "label = load_features(LABEL_FILE)\n",
    "y_train = np.asarray(label['train'])\n",
    "y_test = np.asarray(label['test'])\n",
    "\n",
    "# 便捷变量\n",
    "X_clip_train = feature_data['clip']['train']\n",
    "X_clip_test = feature_data['clip']['test']\n",
    "X_face_train = feature_data['face']['train']\n",
    "X_face_test = feature_data['face']['test']\n",
    "X_bert_train = feature_data['bert']['train']\n",
    "X_bert_test = feature_data['bert']['test']\n",
    "\n",
    "print(f\"\\n训练集: {len(y_train)}, 测试集: {len(y_test)}\")\n",
    "print(f\"Face数据范围: [{X_face_train.min():.2f}, {X_face_train.max():.2f}]\")\n",
    "\n",
    "# 类别信息\n",
    "class_labels = ['Bored', 'Happy', 'Interested', 'Tired', 'Confused']\n",
    "num_classes = 5\n",
    "\n",
    "# 类别权重\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"类别权重: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 编码器定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_SHAPE = FEATURES_CONFIG['clip']['shape']\n",
    "FACE_SHAPE = FEATURES_CONFIG['face']['shape']\n",
    "BERT_SHAPE = FEATURES_CONFIG['bert']['shape']\n",
    "\n",
    "def build_clip_encoder(input_shape=None):\n",
    "    \"\"\"\n",
    "    CLIP编码器: Conv1D x 3 + LSTM -> 64维\n",
    "    \"\"\"\n",
    "    if input_shape is None:\n",
    "        input_shape = CLIP_SHAPE\n",
    "    \n",
    "    inp = Input(input_shape, name='clip_input')\n",
    "    \n",
    "    h = Conv1D(64, 3, 1, 'same', kernel_regularizer=l2(0.001))(inp)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = tf.keras.layers.ReLU()(h)\n",
    "    \n",
    "    h = Conv1D(64, 1, 1, 'same', kernel_regularizer=l2(0.001))(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = tf.keras.layers.ReLU()(h)\n",
    "    \n",
    "    h = Conv1D(64, 3, 1, 'same', kernel_regularizer=l2(0.001))(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = tf.keras.layers.ReLU()(h)\n",
    "    \n",
    "    out = LSTM(64, activation='relu', dropout=0.2, recurrent_dropout=0.2)(h)\n",
    "    \n",
    "    return inp, out  # (batch, 64)\n",
    "\n",
    "\n",
    "def build_face_encoder(input_shape=None):\n",
    "    \"\"\"\n",
    "    Face图像编码器: TimeDistributed CNN + LSTM -> 64维\n",
    "    输入: (16, 224, 224, 3) - 16帧面部图像\n",
    "    \"\"\"\n",
    "    if input_shape is None:\n",
    "        input_shape = FACE_SHAPE\n",
    "    \n",
    "    inp = Input(input_shape, name='face_input')  # (batch, 16, 224, 224, 3)\n",
    "    \n",
    "    # 轻量级CNN (TimeDistributed应用到每一帧)\n",
    "    h = TimeDistributed(Conv2D(32, 3, 2, 'same', kernel_regularizer=l2(0.001)))(inp)  # 112x112\n",
    "    h = TimeDistributed(BatchNormalization())(h)\n",
    "    h = TimeDistributed(tf.keras.layers.ReLU())(h)\n",
    "    h = TimeDistributed(MaxPooling2D(2))(h)  # 56x56\n",
    "    \n",
    "    h = TimeDistributed(Conv2D(64, 3, 2, 'same', kernel_regularizer=l2(0.001)))(h)  # 28x28\n",
    "    h = TimeDistributed(BatchNormalization())(h)\n",
    "    h = TimeDistributed(tf.keras.layers.ReLU())(h)\n",
    "    h = TimeDistributed(MaxPooling2D(2))(h)  # 14x14\n",
    "    \n",
    "    h = TimeDistributed(Conv2D(128, 3, 2, 'same', kernel_regularizer=l2(0.001)))(h)  # 7x7\n",
    "    h = TimeDistributed(BatchNormalization())(h)\n",
    "    h = TimeDistributed(tf.keras.layers.ReLU())(h)\n",
    "    \n",
    "    # 全局池化得到每帧特征\n",
    "    h = TimeDistributed(GlobalAveragePooling2D())(h)  # (batch, 16, 128)\n",
    "    \n",
    "    # LSTM处理时序\n",
    "    out = LSTM(64, activation='relu', dropout=0.2, recurrent_dropout=0.2)(h)\n",
    "    \n",
    "    return inp, out  # (batch, 64)\n",
    "\n",
    "\n",
    "def build_bert_encoder(input_shape=None):\n",
    "    \"\"\"\n",
    "    BERT编码器: Conv1D + Attention + Pool -> 128维\n",
    "    \"\"\"\n",
    "    if input_shape is None:\n",
    "        input_shape = BERT_SHAPE\n",
    "    \n",
    "    inp = Input(input_shape, name='bert_input')\n",
    "    \n",
    "    q = Conv1D(64, 3, 1, kernel_regularizer=l2(0.001))(inp)\n",
    "    v = Conv1D(64, 3, 1, kernel_regularizer=l2(0.001))(inp)\n",
    "    attn = Attention()([q, v])\n",
    "    \n",
    "    q_pool = GlobalAveragePooling1D()(q)\n",
    "    attn_pool = GlobalAveragePooling1D()(attn)\n",
    "    \n",
    "    out = Concatenate()([q_pool, attn_pool])  # (batch, 128)\n",
    "    \n",
    "    return inp, out\n",
    "\n",
    "\n",
    "print(\"编码器定义完成\")\n",
    "print(f\"  CLIP:  {CLIP_SHAPE} -> 64维\")\n",
    "print(f\"  Face:  {FACE_SHAPE} -> 64维 (CNN+LSTM)\")\n",
    "print(f\"  BERT:  {BERT_SHAPE} -> 128维\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 融合策略定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 融合策略 1: Concat ====================\n",
    "def fusion_concat(clip_feat, face_feat, bert_feat):\n",
    "    \"\"\"\n",
    "    简单拼接: 64 + 64 + 128 = 256维\n",
    "    \"\"\"\n",
    "    return Concatenate(name='fusion_concat')([clip_feat, face_feat, bert_feat])\n",
    "\n",
    "\n",
    "# ==================== 融合策略 2: Weighted Sum ====================\n",
    "def fusion_weighted_sum(clip_feat, face_feat, bert_feat):\n",
    "    \"\"\"\n",
    "    三路可学习权重加权求和\n",
    "    输出: 128维\n",
    "    \"\"\"\n",
    "    clip_proj = Dense(128, kernel_regularizer=l2(0.001))(clip_feat)\n",
    "    face_proj = Dense(128, kernel_regularizer=l2(0.001))(face_feat)\n",
    "    bert_proj = Dense(128, kernel_regularizer=l2(0.001))(bert_feat)\n",
    "    \n",
    "    concat_all = Concatenate()([clip_proj, face_proj, bert_proj])\n",
    "    weights = Dense(3, activation='softmax', kernel_regularizer=l2(0.001))(concat_all)\n",
    "    \n",
    "    w1 = Lambda(lambda x: tf.expand_dims(x[:, 0], -1))(weights)\n",
    "    w2 = Lambda(lambda x: tf.expand_dims(x[:, 1], -1))(weights)\n",
    "    w3 = Lambda(lambda x: tf.expand_dims(x[:, 2], -1))(weights)\n",
    "    \n",
    "    fused = Add(name='fusion_weighted_sum')([\n",
    "        Multiply()([clip_proj, w1]),\n",
    "        Multiply()([face_proj, w2]),\n",
    "        Multiply()([bert_proj, w3])\n",
    "    ])\n",
    "    \n",
    "    return fused\n",
    "\n",
    "\n",
    "# ==================== 融合策略 3: Gated ====================\n",
    "def fusion_gated(clip_feat, face_feat, bert_feat):\n",
    "    \"\"\"\n",
    "    三路门控融合\n",
    "    输出: 128维\n",
    "    \"\"\"\n",
    "    clip_proj = Dense(128, kernel_regularizer=l2(0.001))(clip_feat)\n",
    "    face_proj = Dense(128, kernel_regularizer=l2(0.001))(face_feat)\n",
    "    bert_proj = Dense(128, kernel_regularizer=l2(0.001))(bert_feat)\n",
    "    \n",
    "    concat_all = Concatenate()([clip_proj, face_proj, bert_proj])\n",
    "    \n",
    "    gate_clip = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(concat_all)\n",
    "    gate_face = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(concat_all)\n",
    "    gate_bert = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(concat_all)\n",
    "    \n",
    "    gated_clip = Multiply()([clip_proj, gate_clip])\n",
    "    gated_face = Multiply()([face_proj, gate_face])\n",
    "    gated_bert = Multiply()([bert_proj, gate_bert])\n",
    "    \n",
    "    fused = Add(name='fusion_gated')([gated_clip, gated_face, gated_bert])\n",
    "    \n",
    "    return fused\n",
    "\n",
    "\n",
    "# ==================== 融合策略 4: Hierarchical ====================\n",
    "def fusion_hierarchical(clip_feat, face_feat, bert_feat):\n",
    "    \"\"\"\n",
    "    层次融合: 先视觉内融合，再跨模态融合\n",
    "    输出: 128维\n",
    "    \"\"\"\n",
    "    # 视觉内融合 (CLIP + Face)\n",
    "    vis_concat = Concatenate()([clip_feat, face_feat])\n",
    "    vis_gate = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(vis_concat)\n",
    "    \n",
    "    clip_proj = Dense(64, kernel_regularizer=l2(0.001))(clip_feat)\n",
    "    face_proj = Dense(64, kernel_regularizer=l2(0.001))(face_feat)\n",
    "    vis_proj = Concatenate()([clip_proj, face_proj])\n",
    "    \n",
    "    vis_fused = Multiply()([vis_gate, vis_proj])\n",
    "    \n",
    "    # 跨模态融合\n",
    "    combined = Concatenate()([vis_fused, bert_feat])\n",
    "    cross_gate = Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(combined)\n",
    "    \n",
    "    vis_final = Dense(128, kernel_regularizer=l2(0.001))(vis_fused)\n",
    "    tex_final = Dense(128, kernel_regularizer=l2(0.001))(bert_feat)\n",
    "    \n",
    "    fused = Add(name='fusion_hierarchical')([\n",
    "        Multiply()([cross_gate, vis_final]), \n",
    "        Multiply()([Lambda(lambda x: 1-x)(cross_gate), tex_final])\n",
    "    ])\n",
    "    \n",
    "    return fused\n",
    "\n",
    "\n",
    "# ==================== 融合策略 5: Bilinear ====================\n",
    "def fusion_bilinear(clip_feat, face_feat, bert_feat):\n",
    "    \"\"\"\n",
    "    双线性融合\n",
    "    输出: 128维\n",
    "    \"\"\"\n",
    "    clip_proj = Dense(32, kernel_regularizer=l2(0.001))(clip_feat)\n",
    "    face_proj = Dense(32, kernel_regularizer=l2(0.001))(face_feat)\n",
    "    bert_proj = Dense(32, kernel_regularizer=l2(0.001))(bert_feat)\n",
    "    \n",
    "    # clip-face交互\n",
    "    clip_exp = Lambda(lambda x: tf.expand_dims(x, 2))(clip_proj)\n",
    "    face_exp = Lambda(lambda x: tf.expand_dims(x, 1))(face_proj)\n",
    "    bilinear_vis = Lambda(lambda x: x[0] * x[1])([clip_exp, face_exp])\n",
    "    bilinear_vis_flat = Flatten()(bilinear_vis)\n",
    "    \n",
    "    # vis-bert交互\n",
    "    bert_exp = Lambda(lambda x: tf.expand_dims(x, 1))(bert_proj)\n",
    "    bilinear_cross = Lambda(lambda x: x[0] * x[1])([clip_exp, bert_exp])\n",
    "    bilinear_cross_flat = Flatten()(bilinear_cross)\n",
    "    \n",
    "    bilinear_all = Concatenate()([bilinear_vis_flat, bilinear_cross_flat])\n",
    "    bilinear_compressed = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(bilinear_all)\n",
    "    \n",
    "    concat_orig = Concatenate()([clip_feat, face_feat, bert_feat])\n",
    "    concat_proj = Dense(128, kernel_regularizer=l2(0.001))(concat_orig)\n",
    "    \n",
    "    fused = Add(name='fusion_bilinear')([bilinear_compressed, concat_proj])\n",
    "    \n",
    "    return fused\n",
    "\n",
    "\n",
    "# ==================== 融合策略 6: Cross-Attention ====================\n",
    "class MultiHeadCrossAttention(Layer):\n",
    "    def __init__(self, units=64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.wq = Dense(self.units, kernel_regularizer=l2(0.001))\n",
    "        self.wk = Dense(self.units, kernel_regularizer=l2(0.001))\n",
    "        self.wv = Dense(self.units, kernel_regularizer=l2(0.001))\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, query, key_value):\n",
    "        q = self.wq(query)\n",
    "        k = self.wk(key_value)\n",
    "        v = self.wv(key_value)\n",
    "        \n",
    "        scores = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(self.units, tf.float32))\n",
    "        attn_weights = tf.nn.softmax(scores, axis=-1)\n",
    "        output = tf.matmul(attn_weights, v)\n",
    "        return output\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config\n",
    "\n",
    "\n",
    "def fusion_cross_attention(clip_feat, face_feat, bert_feat):\n",
    "    \"\"\"\n",
    "    跨模态注意力融合\n",
    "    输出: 192维\n",
    "    \"\"\"\n",
    "    clip_seq = Lambda(lambda x: tf.expand_dims(x, 1))(clip_feat)\n",
    "    face_seq = Lambda(lambda x: tf.expand_dims(x, 1))(face_feat)\n",
    "    bert_seq = Lambda(lambda x: tf.expand_dims(x, 1))(bert_feat)\n",
    "    \n",
    "    vis_seq = Concatenate(axis=1)([clip_seq, face_seq])\n",
    "    \n",
    "    cross_attn_t2v = MultiHeadCrossAttention(64, name='cross_attn_t2v')\n",
    "    bert_attended = cross_attn_t2v(bert_seq, vis_seq)\n",
    "    bert_out = Lambda(lambda x: tf.squeeze(x, 1))(bert_attended)\n",
    "    \n",
    "    cross_attn_v2t = MultiHeadCrossAttention(64, name='cross_attn_v2t')\n",
    "    clip_attended = cross_attn_v2t(clip_seq, bert_seq)\n",
    "    face_attended = cross_attn_v2t(face_seq, bert_seq)\n",
    "    clip_out = Lambda(lambda x: tf.squeeze(x, 1))(clip_attended)\n",
    "    face_out = Lambda(lambda x: tf.squeeze(x, 1))(face_attended)\n",
    "    \n",
    "    fused = Concatenate(name='fusion_cross_attention')([clip_out, face_out, bert_out])\n",
    "    return fused\n",
    "\n",
    "\n",
    "# ==================== 融合策略 7: Tensor ====================\n",
    "def fusion_tensor(clip_feat, face_feat, bert_feat):\n",
    "    \"\"\"\n",
    "    张量融合\n",
    "    输出: 128维\n",
    "    \"\"\"\n",
    "    clip_proj = Dense(16, kernel_regularizer=l2(0.001))(clip_feat)\n",
    "    face_proj = Dense(16, kernel_regularizer=l2(0.001))(face_feat)\n",
    "    bert_proj = Dense(16, kernel_regularizer=l2(0.001))(bert_feat)\n",
    "    \n",
    "    clip_with_1 = Lambda(lambda x: tf.concat([x, tf.ones_like(x[:, :1])], axis=1))(clip_proj)\n",
    "    face_with_1 = Lambda(lambda x: tf.concat([x, tf.ones_like(x[:, :1])], axis=1))(face_proj)\n",
    "    bert_with_1 = Lambda(lambda x: tf.concat([x, tf.ones_like(x[:, :1])], axis=1))(bert_proj)\n",
    "    \n",
    "    clip_exp = Lambda(lambda x: tf.expand_dims(x, 2))(clip_with_1)\n",
    "    face_exp = Lambda(lambda x: tf.expand_dims(x, 1))(face_with_1)\n",
    "    tensor_vis = Lambda(lambda x: x[0] * x[1])([clip_exp, face_exp])\n",
    "    tensor_vis_flat = Flatten()(tensor_vis)\n",
    "    \n",
    "    vis_compressed = Dense(17, kernel_regularizer=l2(0.001))(tensor_vis_flat)\n",
    "    vis_exp = Lambda(lambda x: tf.expand_dims(x, 2))(vis_compressed)\n",
    "    bert_exp = Lambda(lambda x: tf.expand_dims(x, 1))(bert_with_1)\n",
    "    tensor_all = Lambda(lambda x: x[0] * x[1])([vis_exp, bert_exp])\n",
    "    tensor_flat = Flatten()(tensor_all)\n",
    "    \n",
    "    fused = Dense(128, activation='relu', kernel_regularizer=l2(0.001), name='fusion_tensor')(tensor_flat)\n",
    "    \n",
    "    return fused\n",
    "\n",
    "\n",
    "print(\"融合策略定义完成！\")\n",
    "print(\"  1. Concat: 简单拼接 -> 256维\")\n",
    "print(\"  2. Weighted Sum: 加权求和 -> 128维\")\n",
    "print(\"  3. Gated: 三路门控 -> 128维\")\n",
    "print(\"  4. Hierarchical: 层次融合 -> 128维\")\n",
    "print(\"  5. Bilinear: 双线性交互 -> 128维\")\n",
    "print(\"  6. Cross-Attention: 跨模态注意力 -> 192维\")\n",
    "print(\"  7. Tensor: 张量融合 -> 128维\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(fusion_method='concat', learning_rate=0.0005):\n",
    "    \"\"\"\n",
    "    构建三特征融合模型\n",
    "    \"\"\"\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    # 构建编码器\n",
    "    clip_inp, clip_feat = build_clip_encoder()\n",
    "    face_inp, face_feat = build_face_encoder()\n",
    "    bert_inp, bert_feat = build_bert_encoder()\n",
    "    \n",
    "    # 选择融合策略\n",
    "    fusion_methods = {\n",
    "        'concat': fusion_concat,\n",
    "        'weighted_sum': fusion_weighted_sum,\n",
    "        'gated': fusion_gated,\n",
    "        'hierarchical': fusion_hierarchical,\n",
    "        'bilinear': fusion_bilinear,\n",
    "        'cross_attention': fusion_cross_attention,\n",
    "        'tensor': fusion_tensor\n",
    "    }\n",
    "    \n",
    "    fused = fusion_methods[fusion_method](clip_feat, face_feat, bert_feat)\n",
    "    \n",
    "    # 分类头\n",
    "    h = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(fused)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    h = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(h)\n",
    "    h = Dropout(0.3)(h)\n",
    "    output = Dense(num_classes, activation='softmax', name='output')(h)\n",
    "    \n",
    "    model = Model(inputs=[clip_inp, face_inp, bert_inp], outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['acc']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"模型构建函数完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_run(fusion_method, run_id):\n",
    "    \"\"\"单次训练\"\"\"\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = build_model(fusion_method=fusion_method, learning_rate=0.0005)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True, mode='max', verbose=0),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=5, min_lr=1e-7, mode='max', verbose=0)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=[X_clip_train, X_face_train, X_bert_train],\n",
    "        y=y_train,\n",
    "        batch_size=8,  # Face图像较大，减小batch size\n",
    "        epochs=50,\n",
    "        validation_data=([X_clip_test, X_face_test, X_bert_test], y_test),\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 评估\n",
    "    pred = model.predict([X_clip_test, X_face_test, X_bert_test], verbose=0)\n",
    "    pred_labels = pred.argmax(axis=1)\n",
    "    test_acc = np.mean(pred_labels == y_test)\n",
    "    \n",
    "    report = classification_report(y_test, pred_labels, target_names=class_labels,\n",
    "                                   digits=4, output_dict=True, zero_division=0)\n",
    "    f1_macro = report['macro avg']['f1-score']\n",
    "    cm = confusion_matrix(y_test, pred_labels)\n",
    "    \n",
    "    acc_key = 'acc' if 'acc' in history.history else 'accuracy'\n",
    "    val_acc_key = 'val_acc' if 'val_acc' in history.history else 'val_accuracy'\n",
    "    best_train_acc = max(history.history[acc_key])\n",
    "    best_epoch = history.history[val_acc_key].index(max(history.history[val_acc_key])) + 1\n",
    "    \n",
    "    result = {\n",
    "        'run_id': run_id,\n",
    "        'test_acc': test_acc,\n",
    "        'f1_macro': f1_macro,\n",
    "        'train_acc': best_train_acc,\n",
    "        'best_epoch': best_epoch,\n",
    "        'params': model.count_params(),\n",
    "        'confusion_matrix': cm,\n",
    "        'history': history.history,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def train_and_evaluate(fusion_method, num_runs=5):\n",
    "    \"\"\"多次训练取最好\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"融合策略: {fusion_method.upper()} (重复 {num_runs} 次)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    \n",
    "    all_runs = []\n",
    "    best_model = None\n",
    "    best_acc = -1\n",
    "    best_idx = -1\n",
    "    \n",
    "    for run_id in range(1, num_runs + 1):\n",
    "        print(f\"  Run {run_id}/{num_runs}...\", end=\" \")\n",
    "        result = train_single_run(fusion_method, run_id)\n",
    "        print(f\"ACC: {result['test_acc']:.4f}, F1: {result['f1_macro']:.4f}\")\n",
    "        \n",
    "        if result['test_acc'] > best_acc:\n",
    "            if best_model is not None:\n",
    "                del best_model\n",
    "            best_model = result['model']\n",
    "            best_acc = result['test_acc']\n",
    "            best_idx = run_id - 1\n",
    "        else:\n",
    "            del result['model']\n",
    "        \n",
    "        result_copy = {k: v for k, v in result.items() if k != 'model'}\n",
    "        all_runs.append(result_copy)\n",
    "        \n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    accs = [r['test_acc'] for r in all_runs]\n",
    "    f1s = [r['f1_macro'] for r in all_runs]\n",
    "    \n",
    "    mean_acc, std_acc = np.mean(accs), np.std(accs)\n",
    "    max_acc, min_acc = np.max(accs), np.min(accs)\n",
    "    mean_f1, std_f1 = np.mean(f1s), np.std(f1s)\n",
    "    \n",
    "    best_run = all_runs[best_idx]\n",
    "    \n",
    "    model_path = f'{SAVE_DIR}/model_{fusion_method}.tf'\n",
    "    best_model.save(model_path)\n",
    "    \n",
    "    print(f\"\\n  统计: ACC = {mean_acc:.4f} ± {std_acc:.4f} (max={max_acc:.4f}, min={min_acc:.4f})\")\n",
    "    print(f\"        F1  = {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "    print(f\"  最佳: Run {best_run['run_id']}, ACC = {best_run['test_acc']:.4f}\")\n",
    "    \n",
    "    del best_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    results = {\n",
    "        'method': fusion_method,\n",
    "        'num_runs': num_runs,\n",
    "        'all_accs': accs,\n",
    "        'all_f1s': f1s,\n",
    "        'mean_acc': mean_acc,\n",
    "        'std_acc': std_acc,\n",
    "        'max_acc': max_acc,\n",
    "        'min_acc': min_acc,\n",
    "        'mean_f1': mean_f1,\n",
    "        'std_f1': std_f1,\n",
    "        'best_run': best_run,\n",
    "        'test_acc': best_run['test_acc'],\n",
    "        'f1_macro': best_run['f1_macro'],\n",
    "        'train_acc': best_run['train_acc'],\n",
    "        'best_epoch': best_run['best_epoch'],\n",
    "        'params': best_run['params'],\n",
    "        'confusion_matrix': best_run['confusion_matrix'],\n",
    "        'history': best_run['history']\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"训练评估函数完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 运行实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_methods = ['concat', 'weighted_sum', 'gated', 'hierarchical', 'bilinear', 'cross_attention', 'tensor']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"双模态多特征融合实验 (CLIP + Face + BERT)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Fold: {FOLD}\")\n",
    "print(f\"特征: CLIP {CLIP_SHAPE} + Face {FACE_SHAPE} + BERT {BERT_SHAPE}\")\n",
    "print(f\"融合策略: {fusion_methods}\")\n",
    "print(f\"重复次数: {NUM_RUNS}\")\n",
    "print(f\"保存路径: {SAVE_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行所有实验\n",
    "all_results = {}\n",
    "\n",
    "for method in fusion_methods:\n",
    "    results = train_and_evaluate(method, num_runs=NUM_RUNS)\n",
    "    all_results[method] = results\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"所有实验完成！\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 结果汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果表格\n",
    "results_df = pd.DataFrame({\n",
    "    'Method': [r['method'].upper() for r in all_results.values()],\n",
    "    'Best ACC': [f\"{r['max_acc']:.4f}\" for r in all_results.values()],\n",
    "    'Mean±Std': [f\"{r['mean_acc']:.4f}±{r['std_acc']:.4f}\" for r in all_results.values()],\n",
    "    'Best F1': [f\"{r['f1_macro']:.4f}\" for r in all_results.values()],\n",
    "    'F1 Mean±Std': [f\"{r['mean_f1']:.4f}±{r['std_f1']:.4f}\" for r in all_results.values()],\n",
    "    'Params': [f\"{r['params']:,}\" for r in all_results.values()],\n",
    "})\n",
    "\n",
    "results_df['best_acc_float'] = [r['max_acc'] for r in all_results.values()]\n",
    "results_df = results_df.sort_values('best_acc_float', ascending=False).drop('best_acc_float', axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(f\"融合策略对比结果 (CLIP + Face + BERT, Fold {FOLD})\")\n",
    "print(\"=\"*90)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "csv_path = f'{SAVE_DIR}/results_summary.csv'\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\n结果已保存至: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "sorted_results = sorted(all_results.values(), key=lambda x: x['max_acc'], reverse=True)\n",
    "methods = [r['method'].upper() for r in sorted_results]\n",
    "max_accs = [r['max_acc'] for r in sorted_results]\n",
    "mean_accs = [r['mean_acc'] for r in sorted_results]\n",
    "std_accs = [r['std_acc'] for r in sorted_results]\n",
    "max_f1s = [r['f1_macro'] for r in sorted_results]\n",
    "mean_f1s = [r['mean_f1'] for r in sorted_results]\n",
    "std_f1s = [r['std_f1'] for r in sorted_results]\n",
    "\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c', '#e67e22']\n",
    "x = np.arange(len(methods))\n",
    "\n",
    "bars1 = axes[0].bar(x, max_accs, color=colors[:len(methods)], alpha=0.8, label='Best')\n",
    "axes[0].errorbar(x, mean_accs, yerr=std_accs, fmt='o', color='black', capsize=5, capthick=2, label='Mean±Std')\n",
    "axes[0].set_ylabel('Test Accuracy', fontsize=12)\n",
    "axes[0].set_title(f'Test Accuracy (CLIP+Face+BERT, Fold {FOLD})', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "for bar, acc in zip(bars1, max_accs):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{acc:.4f}', ha='center', fontweight='bold', fontsize=8)\n",
    "\n",
    "bars2 = axes[1].bar(x, max_f1s, color=colors[:len(methods)], alpha=0.8, label='Best')\n",
    "axes[1].errorbar(x, mean_f1s, yerr=std_f1s, fmt='o', color='black', capsize=5, capthick=2, label='Mean±Std')\n",
    "axes[1].set_ylabel('F1 Score (Macro)', fontsize=12)\n",
    "axes[1].set_title(f'F1 Score (CLIP+Face+BERT, Fold {FOLD})', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "for bar, f1 in zip(bars2, max_f1s):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{f1:.4f}', ha='center', fontweight='bold', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (method, results) in enumerate(all_results.items()):\n",
    "    if idx >= 7:\n",
    "        break\n",
    "    ax = axes[idx]\n",
    "    cm = results['confusion_matrix']\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=class_labels, yticklabels=class_labels,\n",
    "                ax=ax, vmin=0, vmax=1)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title(f\"{method.upper()} (ACC: {results['test_acc']:.4f})\", fontweight='bold')\n",
    "\n",
    "if len(all_results) < 8:\n",
    "    axes[7].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 最终总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(all_results.items(), key=lambda x: x[1]['max_acc'], reverse=True)\n",
    "best_method, best_result = sorted_results[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"双模态多特征融合实验 (Face版) - 最终总结\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n【实验配置】\")\n",
    "print(f\"  Fold: {FOLD}\")\n",
    "print(f\"  视觉特征: CLIP {CLIP_SHAPE} + Face {FACE_SHAPE}\")\n",
    "print(f\"  文本特征: BERT {BERT_SHAPE}\")\n",
    "print(f\"  重复次数: {NUM_RUNS}\")\n",
    "\n",
    "print(\"\\n【融合策略排名】\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'排名':<4}{'策略':<18}{'Best ACC':<12}{'Mean±Std':<18}{'Best F1':<10}{'参数量':<12}\")\n",
    "print(\"-\" * 80)\n",
    "for rank, (method, r) in enumerate(sorted_results, 1):\n",
    "    mean_std = f\"{r['mean_acc']:.4f}±{r['std_acc']:.4f}\"\n",
    "    print(f\"{rank:<4}{method.upper():<18}{r['max_acc']:<12.4f}{mean_std:<18}{r['f1_macro']:<10.4f}{r['params']:<12,}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n【最佳融合策略】: {best_method.upper()}\")\n",
    "print(f\"  Best ACC: {best_result['max_acc']:.4f}\")\n",
    "print(f\"  Mean ACC: {best_result['mean_acc']:.4f} ± {best_result['std_acc']:.4f}\")\n",
    "print(f\"  Best F1:  {best_result['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n【保存路径】: {SAVE_DIR}\")\n",
    "print(\"=\"*80)\n",
    "print(\"实验完成！\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}